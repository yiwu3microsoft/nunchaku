<div align="center" id="nunchaku_logo">
  <img src="https://huggingface.co/datasets/nunchaku-tech/cdn/resolve/main/nunchaku/assets/nunchaku.svg" alt="logo" width="220"></img>
</div>
<h3 align="center">
<a href="http://arxiv.org/abs/2411.05007"><b>è®ºæ–‡</b></a> | <a href="https://nunchaku.tech/docs/nunchaku/"><b>æ–‡æ¡£</b></a> | <a href="https://hanlab.mit.edu/projects/svdquant"><b>å®˜ç½‘</b></a> | <a href="https://hanlab.mit.edu/blog/svdquant"><b>åšå®¢</b></a> | <a href="https://svdquant.mit.edu"><b>æ¼”ç¤º</b></a> | <a href="https://huggingface.co/nunchaku-tech"><b>Hugging Face</b></a> | <a href="https://modelscope.cn/organization/nunchaku-tech"><b>é­”æ­ç¤¾åŒº</b></a> | <a href="https://github.com/nunchaku-tech/ComfyUI-nunchaku"><b>ComfyUI</b></a>
</h3>

<h3 align="center">
<a href="README.md"><b>English</b></a> | <a href="README_ZH.md"><b>ä¸­æ–‡</b></a>
</h3>

**Nunchaku** æ˜¯ä¸€æ¬¾ä¸º 4-bit ç¥ç»ç½‘ç»œä¼˜åŒ–çš„é«˜æ€§èƒ½æ¨ç†å¼•æ“ï¼Œè¯¦è§æˆ‘ä»¬çš„è®ºæ–‡ [SVDQuant](http://arxiv.org/abs/2411.05007)ã€‚åº•å±‚é‡åŒ–åº“è¯·å‚è€ƒ [DeepCompressor](https://github.com/nunchaku-tech/deepcompressor)ã€‚

æ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ç”¨æˆ·ç¾¤ï¼š[**Slack**](https://join.slack.com/t/nunchaku/shared_invite/zt-3170agzoz-NgZzWaTrEj~n2KEV3Hpl5Q)ã€[**Discord**](https://discord.gg/Wk6PnwX9Sm) å’Œ [**å¾®ä¿¡**](https://huggingface.co/datasets/nunchaku-tech/cdn/resolve/main/nunchaku/assets/wechat.jpg)ï¼Œä¸ç¤¾åŒºäº¤æµï¼æ›´å¤šè¯¦æƒ…è§ [è¿™é‡Œ](https://github.com/nunchaku-tech/nunchaku/issues/149)ã€‚å¦‚æœ‰é—®é¢˜ã€é‡åˆ° bug æˆ–æœ‰æ„è´¡çŒ®ä»£ç ï¼Œæ¬¢è¿éšæ—¶è”ç³»æˆ‘ä»¬ï¼

## æœ€æ–°åŠ¨æ€

- **[2025-08-27]** ğŸš€ å‘å¸ƒ **4-bit [4/8æ­¥ lightning Qwen-Image](https://huggingface.co/lightx2v/Qwen-Image-Lightning)**ï¼å¯åœ¨ [Hugging Face](https://huggingface.co/nunchaku-tech/nunchaku-qwen-image) å’Œ [ModelScope](https://modelscope.cn/models/nunchaku-tech/nunchaku-qwen-image) ä¸‹è½½ã€‚ä½¿ç”¨æˆ‘ä»¬çš„ [ç¤ºä¾‹è„šæœ¬](examples/v1/qwen-image-lightning.py) å¼€å§‹ä½“éªŒã€‚
- **[2025-07-31]** ğŸš€ **[FLUX.1-Krea-dev](https://www.krea.ai/blog/flux-krea-open-source-release) å·²æ”¯æŒï¼** æ¬¢è¿å‚è€ƒæˆ‘ä»¬çš„[ç¤ºä¾‹è„šæœ¬](./examples/flux.1-krea-dev.py)å¿«é€Ÿä¸Šæ‰‹ã€‚
- **[2025-07-13]** ğŸš€ å®˜æ–¹ [**Nunchaku æ–‡æ¡£**](https://nunchaku.tech/docs/nunchaku/) ä¸Šçº¿ï¼æ¬¢è¿æŸ¥é˜…è¯¦ç»†çš„å…¥é—¨æŒ‡å—å’Œèµ„æºã€‚
- **[2025-06-29]** ğŸ”¥ æ”¯æŒ **FLUX.1-Kontext**ï¼å¯å‚è€ƒæˆ‘ä»¬çš„[ç¤ºä¾‹è„šæœ¬](./examples/flux.1-kontext-dev.py)ä½“éªŒï¼Œåœ¨çº¿æ¼”ç¤ºè§[æ­¤å¤„](https://svdquant.mit.edu/kontext/)ï¼
- **[2025-06-01]** ğŸš€ **v0.3.0 å‘å¸ƒï¼** æœ¬æ¬¡æ›´æ–°æ”¯æŒå¤š batch æ¨ç†ã€[**ControlNet-Union-Pro 2.0**](https://huggingface.co/Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro-2.0)ã€åˆæ­¥é›†æˆ [**PuLID**](https://github.com/ToTheBeginning/PuLID)ï¼Œå¹¶å¼•å…¥ [**åŒ FB Cache**](examples/flux.1-dev-double_cache.py)ã€‚ç°å·²æ”¯æŒå•æ–‡ä»¶åŠ è½½ FLUX æ¨¡å‹ï¼Œå‡çº§åçš„ [**4-bit T5 ç¼–ç å™¨**](https://huggingface.co/nunchaku-tech/nunchaku-t5) è´¨é‡åª²ç¾ **FP8 T5**ï¼

<details>
<summary>æ›´å¤šå†å²</summary>

- **[2025-04-16]** ğŸ¥ å‘å¸ƒä¸­è‹±æ–‡[**å®‰è£…ä¸ä½¿ç”¨æ•™ç¨‹è§†é¢‘**](https://youtu.be/YHAVe-oM7U8?si=cM9zaby_aEHiFXk0)ï¼ˆ[**Bç«™**](https://www.bilibili.com/video/BV1BTocYjEk5/?share_source=copy_web&vd_source=8926212fef622f25cc95380515ac74ee)ï¼‰ã€‚
- **[2025-04-09]** ğŸ“¢ å‘å¸ƒ [å››æœˆè·¯çº¿å›¾](https://github.com/nunchaku-tech/nunchaku/issues/266) åŠ [FAQ](https://github.com/nunchaku-tech/nunchaku/discussions/262)ï¼ŒåŠ©åŠ›ç¤¾åŒºå¿«é€Ÿä¸Šæ‰‹å¹¶äº†è§£æœ€æ–°è¿›å±•ã€‚
- **[2025-04-05]** ğŸš€ **Nunchaku v0.2.0 å‘å¸ƒï¼** æœ¬æ¬¡æ›´æ–°å¸¦æ¥ [**å¤š LoRA**](examples/flux.1-dev-multiple-lora.py) å’Œ [**ControlNet**](examples/flux.1-dev-controlnet-union-pro.py) æ”¯æŒï¼Œå¹¶é€šè¿‡ [**FP16 attention**](#fp16-attention) å’Œ [**First-Block Cache**](#first-block-cache) å®ç°æ›´å¿«æ¨ç†ã€‚ç°å·²å…¼å®¹ [**20 ç³»æ˜¾å¡**](examples/flux.1-dev-turing.py) â€”â€” Nunchaku æ›´æ˜“ç”¨ï¼
- **[2025-03-07]** ğŸš€ **Nunchaku v0.1.4 å‘å¸ƒï¼** æ”¯æŒ [4-bit æ–‡æœ¬ç¼–ç å™¨å’Œé€å±‚ CPU ä¸‹æ”¾](#Low-Memory-Inference)ï¼Œå°† FLUX æœ€ä½æ˜¾å­˜éœ€æ±‚é™è‡³ **4 GiB**ï¼ŒåŒæ—¶å®ç° **2â€“3Ã— åŠ é€Ÿ**ã€‚æœ¬æ¬¡è¿˜ä¿®å¤äº†åˆ†è¾¨ç‡ã€LoRAã€pin memory å’Œç¨³å®šæ€§ç­‰é—®é¢˜ï¼Œè¯¦è§å‘å¸ƒè¯´æ˜ï¼
- **[2025-02-20]** ğŸš€ **RTX 5090 æ”¯æŒ NVFP4 ç²¾åº¦ï¼** NVFP4 ç›¸æ¯” INT4 ç”»è´¨æ›´ä½³ï¼Œåœ¨ RTX 5090 ä¸Šæ¯” BF16 å¿« **~3Ã—**ã€‚è¯¦æƒ…è§[åšå®¢](https://hanlab.mit.edu/blog/svdquant-nvfp4)ï¼Œç”¨æ³•è§ [`examples`](./examples)ï¼Œåœ¨çº¿ä½“éªŒ[ç‚¹æ­¤](https://svdquant.mit.edu/flux1-schnell/)ï¼
- **[2025-02-18]** ğŸ”¥ [**è‡ªå®šä¹‰ LoRA è½¬æ¢**](#Customized-LoRA) å’Œ [**æ¨¡å‹é‡åŒ–**](#Customized-Model-Quantization) æ•™ç¨‹ä¸Šçº¿ï¼**[ComfyUI](./comfyui)** å·¥ä½œæµç°å·²æ”¯æŒ **è‡ªå®šä¹‰ LoRA** åŠ **FLUX.1-Tools**ï¼
- **[2025-02-11]** ğŸ‰ **[SVDQuant](http://arxiv.org/abs/2411.05007) å…¥é€‰ ICLR 2025 Spotlightï¼FLUX.1-tools Gradio æ¼”ç¤ºä¸Šçº¿ï¼** è¯¦æƒ…è§ [è¿™é‡Œ](#gradio-demos)ã€‚å…¨æ–° [depth-to-image æ¼”ç¤º](https://svdquant.mit.edu/flux1-depth-dev/) ä¹Ÿå·²ä¸Šçº¿ï¼Œæ¬¢è¿ä½“éªŒï¼
- **[2025-02-04]** **ğŸš€ 4-bit [FLUX.1-tools](https://blackforestlabs.ai/flux-1-tools/) å‘å¸ƒï¼** æ¨ç†é€Ÿåº¦æ¯”åŸæ¨¡å‹å¿« **2-3Ã—**ã€‚ç”¨æ³•è§ [examples](./examples)ã€‚**ComfyUI é›†æˆå³å°†ä¸Šçº¿ï¼**
- **[2025-01-23]** ğŸš€ **4-bit [SANA](https://nvlabs.github.io/Sana/) æ”¯æŒï¼** æ¨ç†é€Ÿåº¦æ¯” 16-bit æ¨¡å‹å¿« 2-3Ã—ã€‚ç”¨æ³•è§ [ç¤ºä¾‹](examples/sana1.6b_pag.py) å’Œ [éƒ¨ç½²æŒ‡å—](app/sana/t2i)ã€‚åœ¨çº¿ä½“éªŒ [svdquant.mit.edu](https://svdquant.mit.edu)ï¼
- **[2025-01-22]** ğŸ‰ [**SVDQuant**](http://arxiv.org/abs/2411.05007) è¢« **ICLR 2025** å½•ç”¨ï¼
- **[2024-12-08]** æ”¯æŒ [ComfyUI](https://github.com/comfyanonymous/ComfyUI)ã€‚ç”¨æ³•è§ [ComfyUI-nunchaku](https://github.com/nunchaku-tech/ComfyUI-nunchaku)ã€‚
- **[2024-11-07]** ğŸ”¥ æœ€æ–° **W4A4** Diffusion é‡åŒ–å·¥ä½œ [**SVDQuant**](https://hanlab.mit.edu/projects/svdquant) æ­£å¼å‘å¸ƒï¼é‡åŒ–åº“è§ [**DeepCompressor**](https://github.com/nunchaku-tech/deepcompressor)ã€‚

</details>

## æ€»è§ˆ

![teaser](https://huggingface.co/datasets/nunchaku-tech/cdn/resolve/main/nunchaku/assets/teaser.jpg)
**Nunchaku** æ˜¯ä¸€æ¬¾é¢å‘ä½æ¯”ç‰¹ç¥ç»ç½‘ç»œçš„é«˜æ€§èƒ½æ¨ç†å¼•æ“ã€‚å…¶å®ç°äº† **SVDQuant**ï¼Œä¸€ç§é’ˆå¯¹ 4-bit æƒé‡å’Œæ¿€æ´»çš„åè®­ç»ƒé‡åŒ–æŠ€æœ¯ï¼Œèƒ½å¾ˆå¥½åœ°ä¿æŒè§†è§‰è´¨é‡ã€‚åœ¨ 12B FLUX.1-dev ä¸Šï¼Œç›¸æ¯” BF16 æ¨¡å‹å®ç°äº† 3.6Ã— æ˜¾å­˜ç¼©å‡ã€‚é€šè¿‡æ¶ˆé™¤ CPU ä¸‹æ”¾ï¼Œåœ¨ 16GB ç¬”è®°æœ¬ 4090 GPU ä¸Šæ¯” 16-bit æ¨¡å‹å¿« 8.7Ã—ï¼Œæ¯” NF4 W4A16 åŸºçº¿å¿« 3Ã—ã€‚åœ¨ PixArt-âˆ‘ ä¸Šï¼Œè§†è§‰è´¨é‡æ˜¾è‘—ä¼˜äºå…¶ä»– W4A4 ç”šè‡³ W4A8 åŸºçº¿ã€‚"E2E" æŒ‡åŒ…æ‹¬æ–‡æœ¬ç¼–ç å™¨å’Œ VAE è§£ç å™¨çš„ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚

**SVDQuant: é€šè¿‡ä½ç§©åˆ†æ”¯å¸æ”¶å¼‚å¸¸å€¼ï¼Œå®ç° 4-bit Diffusion æ¨¡å‹**<br>
[Muyang Li](https://lmxyy.me)\*ï¼Œ[Yujun Lin](https://yujunlin.com)\*ï¼Œ[Zhekai Zhang](https://hanlab.mit.edu/team/zhekai-zhang)\*ï¼Œ[Tianle Cai](https://www.tianle.website/#/)ï¼Œ[Xiuyu Li](https://xiuyuli.com)ï¼Œ[Junxian Guo](https://github.com/JerryGJX)ï¼Œ[Enze Xie](https://xieenze.github.io)ï¼Œ[Chenlin Meng](https://cs.stanford.edu/~chenlin/)ï¼Œ[Jun-Yan Zhu](https://www.cs.cmu.edu/~junyanz/)ï¼Œ[Song Han](https://hanlab.mit.edu/songhan) <br>
*MIT, NVIDIA, CMU, Princeton, UC Berkeley, SJTU, Pika Labs* <br>

https://github.com/user-attachments/assets/fdd4ab68-6489-4c65-8768-259bd866e8f8

## æ–¹æ³•

#### é‡åŒ–æ–¹æ³• -- SVDQuant

![intuition](https://huggingface.co/datasets/nunchaku-tech/cdn/resolve/main/nunchaku/assets/intuition.gif)SVDQuant æ¦‚è§ˆã€‚é˜¶æ®µ1ï¼šåŸå§‹æ¿€æ´» $\boldsymbol{X}$ å’Œæƒé‡ $\boldsymbol{W}$ éƒ½åŒ…å«å¼‚å¸¸å€¼ï¼Œå¯¼è‡´ 4-bit é‡åŒ–å›°éš¾ã€‚é˜¶æ®µ2ï¼šæˆ‘ä»¬å°†å¼‚å¸¸å€¼ä»æ¿€æ´»è¿ç§»åˆ°æƒé‡ï¼Œå¾—åˆ°æ›´æ–°åçš„æ¿€æ´» $\hat{\boldsymbol{X}}$ å’Œæƒé‡ $\hat{\boldsymbol{W}}$ã€‚æ­¤æ—¶ $\hat{\boldsymbol{X}}$ æ›´æ˜“é‡åŒ–ï¼Œä½† $\hat{\boldsymbol{W}}$ æ›´éš¾ã€‚é˜¶æ®µ3ï¼šSVDQuant è¿›ä¸€æ­¥å°† $\hat{\boldsymbol{W}}$ åˆ†è§£ä¸ºä½ç§©åˆ†æ”¯ $\boldsymbol{L}_1\boldsymbol{L}_2$ å’Œæ®‹å·® $\hat{\boldsymbol{W}}-\boldsymbol{L}_1\boldsymbol{L}_2$ã€‚ä½ç§©åˆ†æ”¯ç”¨ 16-bit ç²¾åº¦è¿è¡Œï¼Œä»è€Œç¼“è§£é‡åŒ–éš¾åº¦ã€‚

#### Nunchaku å¼•æ“è®¾è®¡

![engine](https://huggingface.co/datasets/nunchaku-tech/cdn/resolve/main/nunchaku/assets/engine.jpg) (a) ç›´æ¥ç”¨ rank 32 è·‘ä½ç§©åˆ†æ”¯ä¼šå¸¦æ¥ 57% å»¶è¿Ÿå¼€é”€ï¼Œå› éœ€é¢å¤–è¯»å†™ 16-bit è¾“å…¥/è¾“å‡ºã€‚Nunchaku é€šè¿‡å†…æ ¸èåˆä¼˜åŒ–æ­¤å¼€é”€ã€‚(b) *Down Projection* å’Œ *Quantize* å†…æ ¸è¾“å…¥ç›¸åŒï¼Œ*Up Projection* å’Œ *4-Bit Compute* å†…æ ¸è¾“å‡ºç›¸åŒã€‚ä¸ºå‡å°‘æ•°æ®æ¬è¿ï¼ŒNunchaku å°†å‰ä¸¤è€…å’Œåä¸¤è€…åˆ†åˆ«èåˆã€‚

## æ€§èƒ½

![efficiency](https://huggingface.co/datasets/nunchaku-tech/cdn/resolve/main/nunchaku/assets/efficiency.jpg)SVDQuant å°† 12B FLUX.1 æ¨¡å‹ä½“ç§¯ç¼©å° 3.6Ã—ï¼Œæ˜¾å­˜å ç”¨é™è‡³ 16-bit æ¨¡å‹çš„ 1/3.5ã€‚Nunchaku çš„ INT4 æ¨¡å‹åœ¨æ¡Œé¢å’Œç¬”è®°æœ¬ 4090 ä¸Šæ¯” NF4 W4A16 åŸºçº¿å¿« 3.0Ã—ã€‚åœ¨ç¬”è®°æœ¬ 4090 ä¸Šï¼Œé€šè¿‡æ¶ˆé™¤ CPU ä¸‹æ”¾ï¼Œæ€»åŠ é€Ÿæ¯”è¾¾ 10.1Ã—ã€‚NVFP4 æ¨¡å‹åœ¨ RTX 5090 ä¸Šä¹Ÿæ¯” BF16 å’Œ NF4 å¿« 3.1Ã—ã€‚

## å¿«é€Ÿä¸Šæ‰‹

- [å®‰è£…æŒ‡å—](https://nunchaku.tech/docs/nunchaku/installation/installation.html)
- [ä½¿ç”¨æ•™ç¨‹](https://nunchaku.tech/docs/nunchaku/usage/basic_usage.html)
- [ComfyUI æ’ä»¶ï¼šComfyUI-nunchaku](https://github.com/nunchaku-tech/ComfyUI-nunchaku)
- [è‡ªå®šä¹‰æ¨¡å‹é‡åŒ–ï¼šDeepCompressor](https://github.com/nunchaku-tech/deepcompressor)
- [Gradio æ¼”ç¤ºåº”ç”¨](https://github.com/nunchaku-tech/nunchaku/tree/main/app)
- [å¤ç° SVDQuant è®ºæ–‡ç»“æœ](app/flux.1/t2i)
- [API å‚è€ƒ](https://nunchaku.tech/docs/nunchaku/python_api/nunchaku.html)
- [è´¡çŒ®æŒ‡å—](https://nunchaku.tech/docs/nunchaku/developer/contribution_guide.html)
- [å¸¸è§é—®é¢˜ FAQ](https://nunchaku.tech/docs/nunchaku/faq/faq.html)

## è·¯çº¿å›¾

æš‘æœŸå¼€å‘è®¡åˆ’è§ [è¿™é‡Œ](https://github.com/nunchaku-tech/nunchaku/issues/431)ã€‚

## è”ç³»æˆ‘ä»¬

å¦‚æœ‰ä¼ä¸šåˆä½œã€æŠ€æœ¯å’¨è¯¢ã€èµåŠ©æˆ–åˆä½œæ„å‘ï¼Œè¯·è”ç³» muyangli@mit.eduã€‚

## ç›¸å…³é¡¹ç›®

- [Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models](https://arxiv.org/abs/2211.02048), NeurIPS 2022 & T-PAMI 2023
- [SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2211.10438), ICML 2023
- [Q-Diffusion: Quantizing Diffusion Models](https://arxiv.org/abs/2302.04304), ICCV 2023
- [AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration](https://arxiv.org/abs/2306.00978), MLSys 2024
- [DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models](https://arxiv.org/abs/2402.19481), CVPR 2024
- [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](https://arxiv.org/abs/2405.04532), MLSys 2025
- [SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers](https://arxiv.org/abs/2410.10629), ICLR 2025
- [Radial Attention: $O(n \log n)$ Sparse Attention with Energy Decay for Long Video Generation](https://github.com/mit-han-lab/radial-attention), ArXiv 2025

## å¼•ç”¨

å¦‚æœæ‚¨è§‰å¾— `nunchaku` å¯¹æ‚¨çš„ç ”ç©¶æœ‰ç”¨æˆ–ç›¸å…³ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@inproceedings{
  li2024svdquant,
  title={SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models},
  author={Li*, Muyang and Lin*, Yujun and Zhang*, Zhekai and Cai, Tianle and Li, Xiuyu and Guo, Junxian and Xie, Enze and Meng, Chenlin and Zhu, Jun-Yan and Han, Song},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
```

## è‡´è°¢

æˆ‘ä»¬æ„Ÿè°¢ MIT-IBM Watson AI Labã€MIT å’Œ Amazon Science Hubã€MIT AI Hardware Programã€National Science Foundationã€Packard Foundationã€Dellã€LGã€ç°ä»£å’Œä¸‰æ˜Ÿå¯¹æœ¬ç ”ç©¶çš„æ”¯æŒã€‚æˆ‘ä»¬æ„Ÿè°¢ NVIDIA æèµ çš„ DGX æœåŠ¡å™¨ã€‚æˆ‘ä»¬æ„Ÿè°¢ [First Intelligence](https://www.first-intelligence.com/) å’Œ [Yotta Labs](https://www.yottalabs.ai/) èµåŠ©æˆ‘ä»¬çš„è®¡ç®—èµ„æºã€‚

æˆ‘ä»¬ä½¿ç”¨ [img2img-turbo](https://github.com/GaParmar/img2img-turbo) è®­ç»ƒè‰å›¾åˆ°å›¾åƒçš„ LoRAã€‚æˆ‘ä»¬çš„æ–‡æœ¬åˆ°å›¾åƒå’Œå›¾åƒåˆ°å›¾åƒ UI åˆ†åˆ«åŸºäº [playground-v.25](https://huggingface.co/spaces/playgroundai/playground-v2.5/blob/main/app.py) å’Œ [img2img-turbo](https://github.com/GaParmar/img2img-turbo/blob/main/gradio_sketch2image.py) æ„å»ºã€‚æˆ‘ä»¬çš„å®‰å…¨æ£€æŸ¥å™¨æ¥è‡ª [hart](https://github.com/mit-han-lab/hart)ã€‚

Nunchaku è¿˜å—åˆ°è®¸å¤šå¼€æºåº“çš„å¯å‘ï¼ŒåŒ…æ‹¬ï¼ˆä½†ä¸é™äºï¼‰[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)ã€[vLLM](https://github.com/vllm-project/vllm)ã€[QServe](https://github.com/mit-han-lab/qserve)ã€[AWQ](https://github.com/mit-han-lab/llm-awq)ã€[FlashAttention-2](https://github.com/Dao-AILab/flash-attention) å’Œ [Atom](https://github.com/efeslab/Atom)ã€‚

## Star å†å²

[![Star History Chart](https://api.star-history.com/svg?repos=nunchaku-tech/nunchaku&type=Date)](https://www.star-history.com/#nunchaku-tech/nunchaku&Date)
