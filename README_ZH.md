<div align="center" id="nunchaku_logo">
  <img src="assets/nunchaku.svg" alt="logo" width="220"></img>
</div>
<h3 align="center">
<a href="http://arxiv.org/abs/2411.05007"><b>è®ºæ–‡</b></a> | <a href="https://hanlab.mit.edu/projects/svdquant"><b>å®˜ç½‘</b></a> | <a href="https://hanlab.mit.edu/blog/svdquant"><b>åšå®¢</b></a> | <a href="https://svdquant.mit.edu"><b>æ¼”ç¤º</b></a> | <a href="https://huggingface.co/collections/mit-han-lab/svdquant-67493c2c2e62a1fc6e93f45c"><b>HuggingFace</b></a> | <a href="https://modelscope.cn/collections/svdquant-468e8f780c2641"><b>ModelScope</b></a> | <a href="https://github.com/mit-han-lab/ComfyUI-nunchaku"><b>ComfyUI</b></a>
</h3>

<h3 align="center">
<a href="README.md"><b>English</b></a> | <a href="README_ZH.md"><b>ä¸­æ–‡</b></a>
</h3>

**Nunchaku**æ˜¯ä¸€æ¬¾ä¸“ä¸º4-bitç¥ç»ç½‘ç»œä¼˜åŒ–çš„é«˜æ€§èƒ½æ¨ç†å¼•æ“ï¼ŒåŸºäºæˆ‘ä»¬çš„è®ºæ–‡ [SVDQuant](http://arxiv.org/abs/2411.05007) æå‡ºã€‚åº•å±‚é‡åŒ–åº“è¯·å‚è€ƒ [DeepCompressor](https://github.com/mit-han-lab/deepcompressor)ã€‚

æ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„ç”¨æˆ·ç¾¤ï¼š[**Slack**](https://join.slack.com/t/nunchaku/shared_invite/zt-3170agzoz-NgZzWaTrEj~n2KEV3Hpl5Q)ã€[**Discord**](https://discord.gg/Wk6PnwX9Sm) å’Œ [**å¾®ä¿¡**](https://huggingface.co/mit-han-lab/nunchaku-artifacts/resolve/main/nunchaku/assets/wechat.jpg)ï¼Œä¸ç¤¾åŒºäº¤æµï¼æ›´å¤šè¯¦æƒ…è¯·è§[æ­¤å¤„](https://github.com/mit-han-lab/nunchaku/issues/149)ã€‚å¦‚æœ‰ä»»ä½•é—®é¢˜ã€å»ºè®®æˆ–è´¡çŒ®æ„å‘ï¼Œæ¬¢è¿éšæ—¶è”ç³»ï¼

## æœ€æ–°åŠ¨æ€

- **[2025-04-09]** ğŸ¥ å‘å¸ƒäº†[**è‹±æ–‡**](https://youtu.be/YHAVe-oM7U8?si=cM9zaby_aEHiFXk0)å’Œ[**ä¸­æ–‡**](https://www.bilibili.com/video/BV1BTocYjEk5/?share_source=copy_web&vd_source=8926212fef622f25cc95380515ac74ee)æ•™ç¨‹è§†é¢‘ï¼ŒååŠ©å®‰è£…å’Œä½¿ç”¨Nunchakuã€‚
- **[2025-04-09]** ğŸ“¢ å‘å¸ƒ[å››æœˆå¼€å‘è·¯çº¿å›¾](https://github.com/mit-han-lab/nunchaku/issues/266)å’Œ[å¸¸è§é—®é¢˜è§£ç­”](https://github.com/mit-han-lab/nunchaku/discussions/262)ï¼Œå¸®åŠ©ç¤¾åŒºå¿«é€Ÿä¸Šæ‰‹å¹¶äº†è§£Nunchakuæœ€æ–°è¿›å±•ã€‚
- **[2025-04-05]** ğŸš€ **Nunchaku v0.2.0 å‘å¸ƒï¼** æ”¯æŒ[**å¤šLoRAèåˆ**](examples/flux.1-dev-multiple-lora.py)å’Œ[**ControlNet**](examples/flux.1-dev-controlnet-union-pro.py)ï¼Œé€šè¿‡[**FP16 attention**](#fp16-attention)å’Œ[**First-Block Cache**](#first-block-cache)å®ç°æ›´å¿«çš„æ¨ç†é€Ÿåº¦ã€‚æ–°å¢[**20ç³»æ˜¾å¡æ”¯æŒ**](examples/flux.1-dev-turing.py)ï¼Œè¦†ç›–æ›´å¤šç”¨æˆ·ï¼
- **[2025-03-17]** ğŸš€ å‘å¸ƒNVFP4 4-bité‡åŒ–ç‰ˆ[Shuttle-Jaguar](https://huggingface.co/mit-han-lab/svdq-int4-shuttle-jaguar)å’ŒFLUX.1å·¥å…·é›†ï¼Œå‡çº§INT4 FLUX.1å·¥å…·æ¨¡å‹ã€‚ä»[HuggingFace](https://huggingface.co/collections/mit-han-lab/svdquant-67493c2c2e62a1fc6e93f45c)æˆ–[ModelScope](https://modelscope.cn/collections/svdquant-468e8f780c2641)ä¸‹è½½æ›´æ–°ï¼
- **[2025-03-13]** ğŸ“¦ ComfyUIèŠ‚ç‚¹[ç‹¬ç«‹ä»“åº“](https://github.com/mit-han-lab/ComfyUI-nunchaku)å‘å¸ƒï¼Œå®‰è£…æ›´ä¾¿æ·ï¼èŠ‚ç‚¹ç‰ˆæœ¬v0.1.6ä¸Šçº¿ï¼Œå…¨é¢æ”¯æŒ[4-bit Shuttle-Jaguar](https://huggingface.co/mit-han-lab/svdq-int4-shuttle-jaguar)ï¼
- **[2025-03-07]** ğŸš€ **Nunchaku v0.1.4 å‘å¸ƒï¼** æ”¯æŒ4-bitæ–‡æœ¬ç¼–ç å™¨å’Œåˆ†å±‚CPU offloadingï¼ŒFLUXæœ€ä½æ˜¾å­˜éœ€æ±‚é™è‡³**4 GiB**ï¼ŒåŒæ—¶ä¿æŒ**2â€“3å€åŠ é€Ÿ**ã€‚ä¿®å¤åˆ†è¾¨ç‡ã€LoRAã€å†…å­˜é”å®šç­‰ç¨³å®šæ€§é—®é¢˜ï¼Œè¯¦æƒ…è§æ›´æ–°æ—¥å¿—ï¼
- **[2025-02-20]** ğŸš€ å‘å¸ƒ[é¢„ç¼–è¯‘wheelåŒ…](https://huggingface.co/mit-han-lab/nunchaku)ï¼Œç®€åŒ–å®‰è£…æ­¥éª¤ï¼æŸ¥çœ‹[å®‰è£…æŒ‡å—](#å®‰è£…æŒ‡å—)ï¼
- **[2025-02-20]** ğŸš€ **NVIDIA RTX 5090æ”¯æŒNVFP4ç²¾åº¦ï¼** ç›¸æ¯”INT4ï¼ŒNVFP4ç”»è´¨æ›´ä¼˜ï¼Œåœ¨RTX 5090ä¸Šæ¯”BF16å¿«**çº¦3å€**ã€‚[åšå®¢è¯¦è§£](https://hanlab.mit.edu/blog/svdquant-nvfp4)ï¼Œ[ç¤ºä¾‹ä»£ç ](./examples)åŠ[åœ¨çº¿æ¼”ç¤º](https://svdquant.mit.edu/flux1-schnell/)å·²ä¸Šçº¿ï¼
- **[2025-02-18]** ğŸ”¥ æ–°å¢[è‡ªå®šä¹‰LoRAè½¬æ¢](#è‡ªå®šä¹‰lora)å’Œ[æ¨¡å‹é‡åŒ–](#è‡ªå®šä¹‰æ¨¡å‹é‡åŒ–)æŒ‡å—ï¼[ComfyUI](./comfyui)å·¥ä½œæµæ”¯æŒ**è‡ªå®šä¹‰LoRA**åŠ**FLUX.1å·¥å…·é›†**ï¼
- **[2025-02-11]** ğŸ‰ **[SVDQuant](http://arxiv.org/abs/2411.05007)å…¥é€‰ICLR 2025 Spotlightï¼FLUX.1å·¥å…·é›†ä½¿ç”¨æ¼”ç¤ºä¸Šçº¿ï¼** [ä½¿ç”¨æ¼”ç¤º](#ä½¿ç”¨æ¼”ç¤º)å·²æ›´æ–°ï¼[æ·±åº¦å›¾ç”Ÿæˆæ¼”ç¤º](https://svdquant.mit.edu/flux1-depth-dev/)åŒæ­¥å¼€æ”¾ï¼

<details>
<summary>æ›´å¤šåŠ¨æ€</summary>

- **[2025-02-04]** **ğŸš€ 4-bité‡åŒ–ç‰ˆ[FLUX.1å·¥å…·é›†](https://blackforestlabs.ai/flux-1-tools/)å‘å¸ƒï¼** ç›¸æ¯”åŸæ¨¡å‹æé€Ÿ**2-3å€**ã€‚[ç¤ºä¾‹ä»£ç ](./examples)å·²æ›´æ–°ï¼Œ**ComfyUIæ”¯æŒå³å°†åˆ°æ¥ï¼**
- **[2025-01-23]** ğŸš€ **æ”¯æŒ4-bité‡åŒ–[SANA](https://nvlabs.github.io/Sana/)ï¼** ç›¸æ¯”16ä½æ¨¡å‹æé€Ÿ2-3å€ã€‚[ä½¿ç”¨ç¤ºä¾‹](./examples/sana_1600m_pag.py)å’Œ[éƒ¨ç½²æŒ‡å—](app/sana/t2i)å·²å‘å¸ƒï¼Œä½“éªŒ[åœ¨çº¿æ¼”ç¤º](https://svdquant.mit.edu)ï¼
- **[2025-01-22]** ğŸ‰ [**SVDQuant**](http://arxiv.org/abs/2411.05007) è¢« **ICLR 2025** æ¥æ”¶ï¼
- **[2024-12-08]** æ”¯æŒ [ComfyUI](https://github.com/comfyanonymous/ComfyUI)ï¼Œè¯¦æƒ…è§ [mit-han-lab/ComfyUI-nunchaku](https://github.com/mit-han-lab/ComfyUI-nunchaku)ã€‚
- **[2024-11-07]** ğŸ”¥ æœ€æ–° **W4A4** æ‰©æ•£æ¨¡å‹é‡åŒ–å·¥ä½œ [**SVDQuant**](https://hanlab.mit.edu/projects/svdquant) å¼€æºï¼é‡åŒ–åº“ [**DeepCompressor**](https://github.com/mit-han-lab/deepcompressor) åŒæ­¥å‘å¸ƒã€‚

</details>

## é¡¹ç›®æ¦‚è§ˆ

![teaser](https://huggingface.co/mit-han-lab/nunchaku-artifacts/resolve/main/nunchaku/assets/teaser.jpg)
SVDQuant æ˜¯ä¸€ç§æ”¯æŒ4-bitæƒé‡å’Œæ¿€æ´»çš„åè®­ç»ƒé‡åŒ–æŠ€æœ¯ï¼Œèƒ½æœ‰æ•ˆä¿æŒè§†è§‰è´¨é‡ã€‚åœ¨12B FLUX.1-devæ¨¡å‹ä¸Šï¼Œç›¸æ¯”BF16æ¨¡å‹å®ç°äº†3.6å€å†…å­˜å‹ç¼©ã€‚é€šè¿‡æ¶ˆé™¤CPU offloadingï¼Œåœ¨16GBç¬”è®°æœ¬RTX 4090ä¸Šæ¯”16ä½æ¨¡å‹å¿«8.7å€ï¼Œæ¯”NF4 W4A16åŸºçº¿å¿«3å€ã€‚åœ¨PixArt-âˆ‘æ¨¡å‹ä¸Šï¼Œå…¶è§†è§‰è´¨é‡æ˜¾è‘—ä¼˜äºå…¶ä»–W4A4ç”šè‡³W4A8æ–¹æ¡ˆã€‚"E2E"è¡¨ç¤ºåŒ…å«æ–‡æœ¬ç¼–ç å™¨å’ŒVAEè§£ç å™¨çš„ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚

**SVDQuant: é€šè¿‡ä½ç§©åˆ†é‡å¸æ”¶å¼‚å¸¸å€¼å®ç°4-bitæ‰©æ•£æ¨¡å‹é‡åŒ–**<br>
[Muyang Li](https://lmxyy.me)\*, [Yujun Lin](https://yujunlin.com)\*, [Zhekai Zhang](https://hanlab.mit.edu/team/zhekai-zhang)\*, [Tianle Cai](https://www.tianle.website/#/), [Xiuyu Li](https://xiuyuli.com), [Junxian Guo](https://github.com/JerryGJX), [Enze Xie](https://xieenze.github.io), [Chenlin Meng](https://cs.stanford.edu/~chenlin/), [Jun-Yan Zhu](https://www.cs.cmu.edu/~junyanz/), [Song Han](https://hanlab.mit.edu/songhan) <br>
*éº»çœç†å·¥å­¦é™¢ã€è‹±ä¼Ÿè¾¾ã€å¡å†…åŸºæ¢…éš†å¤§å­¦ã€æ™®æ—æ–¯é¡¿å¤§å­¦ã€åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡ã€ä¸Šæµ·äº¤é€šå¤§å­¦ã€pikaå®éªŒå®¤* <br>

https://github.com/user-attachments/assets/fdd4ab68-6489-4c65-8768-259bd866e8f8

## æ–¹æ³•åŸç†

#### é‡åŒ–æ–¹æ³• -- SVDQuant

![intuition](https://huggingface.co/mit-han-lab/nunchaku-artifacts/resolve/main/nunchaku/assets/intuition.gif)SVDQuantä¸‰é˜¶æ®µç¤ºæ„å›¾ã€‚é˜¶æ®µ1ï¼šåŸå§‹æ¿€æ´» $\boldsymbol{X}$ å’Œæƒé‡ $\boldsymbol{W}$ å‡å«å¼‚å¸¸å€¼ï¼Œ4-bité‡åŒ–å›°éš¾ã€‚é˜¶æ®µ2ï¼šå°†æ¿€æ´»å¼‚å¸¸å€¼è¿ç§»è‡³æƒé‡ï¼Œå¾—åˆ°æ›´æ˜“é‡åŒ–çš„æ¿€æ´» $\hat{\boldsymbol{X}}$ å’Œæ›´éš¾é‡åŒ–çš„æƒé‡ $\hat{\boldsymbol{W}}$ ã€‚é˜¶æ®µ3ï¼šé€šè¿‡SVDå°† $\hat{\boldsymbol{W}}$ åˆ†è§£ä¸ºä½ç§©åˆ†é‡ $\boldsymbol{L}_1\boldsymbol{L}_2$ å’Œæ®‹å·® $\hat{\boldsymbol{W}}-\boldsymbol{L}_1\boldsymbol{L}_2$ ï¼Œä½ç§©åˆ†æ”¯ä»¥16ä½ç²¾åº¦è¿è¡Œç¼“è§£é‡åŒ–éš¾åº¦ã€‚

#### Nunchakuå¼•æ“è®¾è®¡

![engine](https://huggingface.co/mit-han-lab/nunchaku-artifacts/resolve/main/nunchaku/assets/engine.jpg) (a) åŸå§‹ä½ç§©åˆ†æ”¯ï¼ˆç§©32ï¼‰å› é¢å¤–è¯»å†™16ä½æ•°æ®å¼•å…¥57%çš„å»¶è¿Ÿã€‚Nunchakué€šè¿‡æ ¸èåˆä¼˜åŒ–ã€‚(b) å°†ä¸‹æŠ•å½±ä¸é‡åŒ–ã€ä¸ŠæŠ•å½±ä¸4-bitè®¡ç®—åˆ†åˆ«èåˆï¼Œå‡å°‘æ•°æ®æ¬è¿ã€‚

## æ€§èƒ½è¡¨ç°

![efficiency](https://huggingface.co/mit-han-lab/nunchaku-artifacts/resolve/main/nunchaku/assets/efficiency.jpg)SVDQuant å°†12B FLUX.1æ¨¡å‹çš„ä½“ç§¯å‹ç¼©äº†3.6å€ï¼ŒåŒæ—¶å°†åŸå§‹16ä½æ¨¡å‹çš„æ˜¾å­˜å ç”¨å‡å°‘äº†3.5å€ã€‚å€ŸåŠ©Nunchakuï¼Œæˆ‘ä»¬çš„INT4æ¨¡å‹åœ¨æ¡Œé¢å’Œç¬”è®°æœ¬çš„NVIDIA RTX 4090 GPUä¸Šæ¯”NF4 W4A16åŸºçº¿å¿«äº†3.0å€ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨ç¬”è®°æœ¬4090ä¸Šï¼Œé€šè¿‡æ¶ˆé™¤CPU offloadingï¼Œæ€»ä½“åŠ é€Ÿè¾¾åˆ°äº†10.1å€ã€‚æˆ‘ä»¬çš„NVFP4æ¨¡å‹åœ¨RTX 5090 GPUä¸Šä¹Ÿæ¯”BF16å’ŒNF4å¿«äº†3.1å€ã€‚

## å®‰è£…æŒ‡å—

æˆ‘ä»¬æä¾›äº†åœ¨ Windows ä¸Šå®‰è£…å’Œä½¿ç”¨ Nunchaku çš„æ•™å­¦è§†é¢‘ï¼Œæ”¯æŒ[**è‹±æ–‡**](https://youtu.be/YHAVe-oM7U8?si=cM9zaby_aEHiFXk0)å’Œ[**ä¸­æ–‡**](https://www.bilibili.com/video/BV1BTocYjEk5/?share_source=copy_web&vd_source=8926212fef622f25cc95380515ac74ee)ä¸¤ä¸ªç‰ˆæœ¬ã€‚åŒæ—¶ï¼Œä½ ä¹Ÿå¯ä»¥å‚è€ƒå¯¹åº”çš„å›¾æ–‡æ•™ç¨‹ [`docs/setup_windows.md`](docs/setup_windows.md)ã€‚å¦‚æœåœ¨å®‰è£…è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œå»ºè®®ä¼˜å…ˆæŸ¥é˜…è¿™äº›èµ„æºã€‚

### WheelåŒ…å®‰è£…

#### å‰ç½®æ¡ä»¶
ç¡®ä¿å·²å®‰è£… [PyTorch>=2.5](https://pytorch.org/)ã€‚ä¾‹å¦‚ï¼š

```shell
pip install torch==2.6 torchvision==0.21 torchaudio==2.6
```

#### å®‰è£…nunchaku
ä»[Hugging Face](https://huggingface.co/mit-han-lab/nunchaku/tree/main)ã€[ModelScope](https://modelscope.cn/models/Lmxyy1999/nunchaku)æˆ–[GitHub release](https://github.com/mit-han-lab/nunchaku/releases)é€‰æ‹©å¯¹åº”Pythonå’ŒPyTorchç‰ˆæœ¬çš„wheelã€‚ä¾‹å¦‚Python 3.11å’ŒPyTorch 2.6ï¼š

```shell
pip install https://huggingface.co/mit-han-lab/nunchaku/resolve/main/nunchaku-0.2.0+torch2.6-cp311-cp311-linux_x86_64.whl
```

##### ComfyUIç”¨æˆ·

è‹¥ä½¿ç”¨**ComfyUIä¾¿æºåŒ…**ï¼Œè¯·ç¡®ä¿å°†`nunchaku`å®‰è£…åˆ°ComfyUIè‡ªå¸¦çš„Pythonç¯å¢ƒã€‚æŸ¥çœ‹ComfyUIæ—¥å¿—è·å–Pythonè·¯å¾„ï¼š

```text
** Python executable: G:\ComfyuI\python\python.exe
```

ä½¿ç”¨è¯¥Pythonå®‰è£…wheelï¼š

```shell
"G:\ComfyUI\python\python.exe" -m pip install <your-wheel-file>.whl
```

**ç¤ºä¾‹**ï¼šä¸ºPython 3.11å’ŒPyTorch 2.6å®‰è£…ï¼š

```shell
"G:\ComfyUI\python\python.exe" -m pip install https://github.com/mit-han-lab/nunchaku/releases/download/v0.2.0/nunchaku-0.2.0+torch2.6-cp311-cp311-linux_x86_64.whl
```

##### Blackwellæ˜¾å¡ç”¨æˆ·ï¼ˆ50ç³»åˆ—ï¼‰

è‹¥ä½¿ç”¨Blackwellæ˜¾å¡ï¼ˆå¦‚50ç³»åˆ—ï¼‰ï¼Œè¯·å®‰è£…PyTorch 2.7åŠä»¥ä¸Šç‰ˆæœ¬ï¼Œå¹¶ä½¿ç”¨**FP4æ¨¡å‹**ã€‚

### æºç ç¼–è¯‘

**æ³¨æ„**ï¼š

* Linuxéœ€CUDAâ‰¥12.2ï¼ŒWindowséœ€CUDAâ‰¥12.6ã€‚Blackwellæ˜¾å¡éœ€CUDAâ‰¥12.8ã€‚
* Windowsç”¨æˆ·è¯·å‚è€ƒ[æ­¤é—®é¢˜](https://github.com/mit-han-lab/nunchaku/issues/6)å‡çº§MSVCç¼–è¯‘å™¨ã€‚
* æ”¯æŒSM_75ï¼ˆTuringï¼šRTX 2080ï¼‰ã€SM_86ï¼ˆAmpereï¼šRTX 3090ï¼‰ã€SM_89ï¼ˆAdaï¼šRTX 4090ï¼‰ã€SM_80ï¼ˆA100ï¼‰æ¶æ„æ˜¾å¡ï¼Œè¯¦è§[æ­¤é—®é¢˜](https://github.com/mit-han-lab/nunchaku/issues/1)ã€‚

1. å®‰è£…ä¾èµ–ï¼š

   ```shell
   conda create -n nunchaku python=3.11
   conda activate nunchaku
   pip install torch torchvision torchaudio
   pip install ninja wheel diffusers transformers accelerate sentencepiece protobuf huggingface_hub

   # Gradioæ¼”ç¤ºä¾èµ–
   pip install peft opencv-python gradio spaces GPUtil
   ```

   Blackwellç”¨æˆ·éœ€å®‰è£…PyTorch nightlyï¼ˆCUDA 12.8ï¼‰ï¼š

   ```shell
   pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
   ```

2. ç¼–è¯‘å®‰è£…ï¼š
   ç¡®ä¿`gcc/g++â‰¥11`ã€‚Linuxç”¨æˆ·å¯é€šè¿‡Condaå®‰è£…ï¼š

    ```shell
    conda install -c conda-forge gxx=11 gcc=11
    ```

    Windowsç”¨æˆ·è¯·å®‰è£…æœ€æ–°[Visual Studio](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community&channel=Release&version=VS2022&source=VSLandingPage&cid=2030&passive=false)ã€‚

    ç¼–è¯‘å‘½ä»¤ï¼š

    ```shell
    git clone https://github.com/mit-han-lab/nunchaku.git
    cd nunchaku
    git submodule init
    git submodule update
    python setup.py develop
    ```

    æ‰“åŒ…wheelï¼š

    ```shell
    NUNCHAKU_INSTALL_MODE=ALL NUNCHAKU_BUILD_WHEELS=1 python -m build --wheel --no-isolation
    ```

    è®¾ç½®`NUNCHAKU_INSTALL_MODE=ALL`ç¡®ä¿wheelæ”¯æŒæ‰€æœ‰æ˜¾å¡æ¶æ„ã€‚

## ä½¿ç”¨ç¤ºä¾‹

åœ¨[ç¤ºä¾‹](examples)ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†è¿è¡Œ4-bit[FLUX.1](https://github.com/black-forest-labs/flux)å’Œ[SANA](https://github.com/NVlabs/Sana)æ¨¡å‹çš„æç®€è„šæœ¬ï¼ŒAPIä¸[diffusers](https://github.com/huggingface/diffusers)å…¼å®¹ã€‚ä¾‹å¦‚[FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev)è„šæœ¬ï¼š

```python
import torch
from diffusers import FluxPipeline

from nunchaku import NunchakuFluxTransformer2dModel
from nunchaku.utils import get_precision

precision = get_precision()  # è‡ªåŠ¨æ£€æµ‹GPUæ”¯æŒçš„ç²¾åº¦ï¼ˆint4æˆ–fp4ï¼‰
transformer = NunchakuFluxTransformer2dModel.from_pretrained(f"mit-han-lab/svdq-{precision}-flux.1-dev")
pipeline = FluxPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-dev", transformer=transformer, torch_dtype=torch.bfloat16
).to("cuda")
image = pipeline("ä¸¾ç€'Hello World'æ ‡ç‰Œçš„çŒ«å’ª", num_inference_steps=50, guidance_scale=3.5).images[0]
image.save(f"flux.1-dev-{precision}.png")
```

**æ³¨æ„**ï¼š**Turingæ˜¾å¡ç”¨æˆ·ï¼ˆå¦‚20ç³»åˆ—ï¼‰**éœ€è®¾ç½®`torch_dtype=torch.float16`å¹¶ä½¿ç”¨`nunchaku-fp16`æ³¨æ„åŠ›æ¨¡å—ï¼Œå®Œæ•´ç¤ºä¾‹è§[`examples/flux.1-dev-turing.py`](examples/flux.1-dev-turing.py)ã€‚

### FP16 Attention

é™¤FlashAttention-2å¤–ï¼ŒNunchakuæä¾›å®šåˆ¶FP16 Attentionå®ç°ï¼Œåœ¨30/40/50ç³»æ˜¾å¡ä¸Šæé€Ÿ**1.2å€**ä¸”æ— æŸç²¾åº¦ã€‚å¯ç”¨æ–¹å¼ï¼š

```python
transformer.set_attention_impl("nunchaku-fp16")
```

å®Œæ•´ç¤ºä¾‹è§[`examples/flux.1-dev-fp16attn.py`](examples/flux.1-dev-fp16attn.py)ã€‚

### First-Block Cache

Nunchakuæ”¯æŒ[First-Block Cache](https://github.com/chengzeyi/ParaAttention?tab=readme-ov-file#first-block-cache-our-dynamic-caching)åŠ é€Ÿé•¿æ­¥å»å™ªã€‚å¯ç”¨æ–¹å¼ï¼š

```python
apply_cache_on_pipe(pipeline, residual_diff_threshold=0.12)
```

`residual_diff_threshold`è¶Šå¤§é€Ÿåº¦è¶Šå¿«ä½†å¯èƒ½å½±å“è´¨é‡ï¼Œæ¨èå€¼`0.12`ï¼Œ50æ­¥æ¨ç†æé€Ÿ2å€ï¼Œ30æ­¥æé€Ÿ1.4å€ã€‚å®Œæ•´ç¤ºä¾‹è§[`examples/flux.1-dev-cache.py`](examples/flux.1-dev-cache.py)ã€‚

### CPU offloading

æœ€å°åŒ–æ˜¾å­˜å ç”¨è‡³**4 GiB**ï¼Œè®¾ç½®`offload=True`å¹¶å¯ç”¨CPU offloadingï¼š

```python
pipeline.enable_sequential_cpu_offload()
```

å®Œæ•´ç¤ºä¾‹è§[`examples/flux.1-dev-offload.py`](examples/flux.1-dev-offload.py)ã€‚

## è‡ªå®šä¹‰LoRA

![lora](https://huggingface.co/mit-han-lab/nunchaku-artifacts/resolve/main/nunchaku/assets/lora.jpg)

[SVDQuant](http://arxiv.org/abs/2411.05007) å¯ä»¥æ— ç¼é›†æˆç°æœ‰çš„ LoRAï¼Œè€Œæ— éœ€é‡æ–°é‡åŒ–ã€‚ä½ å¯ä»¥ç®€å•åœ°é€šè¿‡ä»¥ä¸‹æ–¹å¼ä½¿ç”¨ä½ çš„ LoRAï¼š

```python
transformer.update_lora_params(path_to_your_lora)
transformer.set_lora_strength(lora_strength)
```

`path_to_your_lora` ä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªè¿œç¨‹çš„ HuggingFace è·¯å¾„ã€‚åœ¨ [`examples/flux.1-dev-lora.py`](examples/flux.1-dev-lora.py) ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè¿è¡Œ [Ghibsky](https://huggingface.co/aleksa-codes/flux-ghibsky-illustration) LoRA çš„æœ€å°ç¤ºä¾‹è„šæœ¬ï¼Œç»“åˆäº† SVDQuant çš„ 4-bit FLUX.1-devï¼š

```python
import torch
from diffusers import FluxPipeline

from nunchaku import NunchakuFluxTransformer2dModel
from nunchaku.utils import get_precision

precision = get_precision()  # è‡ªåŠ¨æ£€æµ‹ä½ çš„ç²¾åº¦æ˜¯ 'int4' è¿˜æ˜¯ 'fp4'ï¼Œå–å†³äºä½ çš„ GPU
transformer = NunchakuFluxTransformer2dModel.from_pretrained(f"mit-han-lab/svdq-{precision}-flux.1-dev")
pipeline = FluxPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-dev", transformer=transformer, torch_dtype=torch.bfloat16
).to("cuda")

### LoRA ç›¸å…³ä»£ç  ###
transformer.update_lora_params(
    "aleksa-codes/flux-ghibsky-illustration/lora.safetensors"
)  # ä½ çš„ LoRA safetensors è·¯å¾„ï¼Œä¹Ÿå¯ä»¥æ˜¯è¿œç¨‹ HuggingFace è·¯å¾„
transformer.set_lora_strength(1)  # åœ¨è¿™é‡Œè®¾ç½®ä½ çš„ LoRA å¼ºåº¦
### LoRA ç›¸å…³ä»£ç ç»“æŸ ###

image = pipeline(
    "GHIBSKY é£æ ¼ï¼Œè¢«é›ªè¦†ç›–çš„èˆ’é€‚å±±é—´å°å±‹ï¼ŒçƒŸå›±é‡Œå†’å‡ºè¢…è¢…ç‚ŠçƒŸï¼Œçª—æˆ·é€å‡ºæ¸©æš–è¯±äººçš„ç¯å…‰",  # noqa: E501
    num_inference_steps=25,
    guidance_scale=3.5,
).images[0]
image.save(f"flux.1-dev-ghibsky-{precision}.png")
```

å¦‚æœéœ€è¦ç»„åˆå¤šä¸ª LoRAï¼Œå¯ä»¥ä½¿ç”¨ `nunchaku.lora.flux.compose.compose_lora` æ¥å®ç°ç»„åˆã€‚ç”¨æ³•å¦‚ä¸‹ï¼š

```python
composed_lora = compose_lora(
    [
        ("PATH_OR_STATE_DICT_OF_LORA1", lora_strength1),
        ("PATH_OR_STATE_DICT_OF_LORA2", lora_strength2),
        # æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤š LoRA
    ]
)  # åœ¨ä½¿ç”¨ç»„åˆ LoRA æ—¶åœ¨æ­¤å¤„è®¾ç½®æ¯ä¸ª LoRA çš„å¼ºåº¦
transformer.update_lora_params(composed_lora)
```

ä½ å¯ä»¥ä¸ºåˆ—è¡¨ä¸­çš„æ¯ä¸ª LoRA æŒ‡å®šå•ç‹¬çš„å¼ºåº¦ã€‚å®Œæ•´çš„ç¤ºä¾‹è¯·å‚è€ƒ [`examples/flux.1-dev-multiple-lora.py`](examples/flux.1-dev-multiple-lora.py)ã€‚

**å¯¹äº ComfyUI ç”¨æˆ·ï¼Œä½ å¯ä»¥ç›´æ¥ä½¿ç”¨æˆ‘ä»¬çš„ LoRA åŠ è½½å™¨ã€‚è½¬æ¢åçš„ LoRA å·²è¢«å¼ƒç”¨ï¼Œè¯·å‚è€ƒ [mit-han-lab/ComfyUI-nunchaku](https://github.com/mit-han-lab/ComfyUI-nunchaku) è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚**

## ControlNets

Nunchaku æ”¯æŒ [FLUX.1-tools](https://blackforestlabs.ai/flux-1-tools/) å’Œ [FLUX.1-dev-ControlNet-Union-Pro](https://huggingface.co/Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro) æ¨¡å‹ã€‚ç¤ºä¾‹è„šæœ¬å¯ä»¥åœ¨ [`examples`](examples) ç›®å½•ä¸­æ‰¾åˆ°ã€‚

![control](https://huggingface.co/mit-han-lab/nunchaku-artifacts/resolve/main/nunchaku/assets/control.jpg)

## ComfyUI

è¯·å‚è€ƒ [mit-han-lab/ComfyUI-nunchaku](https://github.com/mit-han-lab/ComfyUI-nunchaku) è·å–åœ¨ [ComfyUI](https://github.com/comfyanonymous/ComfyUI) ä¸­çš„ä½¿ç”¨æ–¹æ³•ã€‚

## ä½¿ç”¨æ¼”ç¤º

* FLUX.1 æ¨¡å‹
  * æ–‡ç”Ÿå›¾ï¼šè§ [`app/flux.1/t2i`](app/flux.1/t2i)ã€‚
  * è‰å›¾ç”Ÿæˆå›¾åƒ ([pix2pix-Turbo](https://github.com/GaParmar/img2img-turbo))ï¼šè§ [`app/flux.1/sketch`](app/flux.1/sketch)ã€‚
  * æ·±åº¦/Canny è¾¹ç¼˜ç”Ÿæˆå›¾åƒ ([FLUX.1-tools](https://blackforestlabs.ai/flux-1-tools/))ï¼šè§ [`app/flux.1/depth_canny`](app/flux.1/depth_canny)ã€‚
  * ä¿®å¤ ([FLUX.1-Fill-dev](https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev))ï¼šè§ [`app/flux.1/fill`](app/flux.1/fill)ã€‚
  * Redux ([FLUX.1-Redux-dev](https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev))ï¼šè§ [`app/flux.1/redux`](app/flux.1/redux)ã€‚
* SANAï¼š
  * æ–‡ç”Ÿå›¾ï¼šè§ [`app/sana/t2i`](app/sana/t2i)ã€‚

## è‡ªå®šä¹‰æ¨¡å‹é‡åŒ–

è¯·å‚è€ƒ [mit-han-lab/deepcompressor](https://github.com/mit-han-lab/deepcompressor/tree/main/examples/diffusion)ã€‚æ›´ç®€å•çš„æµç¨‹å³å°†æ¨å‡ºã€‚

## åŸºå‡†æµ‹è¯•

è¯·å‚è€ƒ [app/flux/t2i/README.md](app/flux/t2i/README.md) è·å–é‡ç°æˆ‘ä»¬è®ºæ–‡è´¨é‡ç»“æœå’Œå¯¹ FLUX.1 æ¨¡å‹è¿›è¡Œæ¨ç†å»¶è¿ŸåŸºå‡†æµ‹è¯•çš„è¯´æ˜ã€‚

## è·¯çº¿å›¾

è¯·æŸ¥çœ‹ [æ­¤å¤„](https://github.com/mit-han-lab/nunchaku/issues/266) è·å–å››æœˆçš„è·¯çº¿å›¾ã€‚

## è´¡çŒ®
æˆ‘ä»¬è¯šæŒšæ¬¢è¿ç¤¾åŒºè´¡çŒ®ï¼è¯·å‚é˜…[è´¡çŒ®æŒ‡å—](docs/contribution_guide_ZH.md)äº†è§£å¦‚ä½•ä¸º Nunchaku è´¡çŒ®ä»£ç ã€‚

## é—®é¢˜æ’æŸ¥

ä½¿ç”¨ Nunchaku æ—¶é‡åˆ°é—®é¢˜ï¼Ÿè¯·å…ˆæŸ¥é˜…æˆ‘ä»¬çš„[å¸¸è§é—®é¢˜è§£ç­”](docs/faq_ZH.md)å¯»æ‰¾è§£å†³æ–¹æ¡ˆã€‚è‹¥ä»éœ€è¦å¸®åŠ©ï¼Œå¯é€šè¿‡[open an issue](https://github.com/mit-han-lab/nunchaku/issues)è”ç³»æˆ‘ä»¬ã€‚ä¹Ÿæ¬¢è¿æ‚¨é€šè¿‡ [**Slack**](https://join.slack.com/t/nunchaku/shared_invite/zt-3170agzoz-NgZzWaTrEj~n2KEV3Hpl5Q)ã€[**Discord**](https://discord.gg/Wk6PnwX9Sm) æˆ– [**å¾®ä¿¡**](https://huggingface.co/mit-han-lab/nunchaku-artifacts/resolve/main/nunchaku/assets/wechat.jpg) åŠ å…¥æˆ‘ä»¬çš„ç¤¾åŒºè®¨è®ºã€‚

## è”ç³»æˆ‘ä»¬

æœ‰æ„é‡‡ç”¨ SVDQuant æˆ– Nunchaku çš„ä¼ä¸šï¼ŒåŒ…æ‹¬æŠ€æœ¯å’¨è¯¢ã€èµåŠ©æœºä¼šæˆ–åˆä½œå’¨è¯¢ï¼Œè¯·è”ç³» muyangli@mit.eduã€‚

## ç›¸å…³é¡¹ç›®

* [Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models](https://arxiv.org/abs/2211.02048), NeurIPS 2022 & T-PAMI 2023
* [SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2211.10438), ICML 2023
* [Q-Diffusion: Quantizing Diffusion Models](https://arxiv.org/abs/2302.04304), ICCV 2023
* [AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration](https://arxiv.org/abs/2306.00978), MLSys 2024
* [DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models](https://arxiv.org/abs/2402.19481), CVPR 2024
* [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](https://arxiv.org/abs/2405.04532), MLSys 2025
* [SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers](https://arxiv.org/abs/2410.10629), ICLR 2025

## å¼•ç”¨

å¦‚æœä½ è§‰å¾— `nunchaku` å¯¹ä½ çš„ç ”ç©¶æœ‰ç”¨æˆ–ç›¸å…³ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@inproceedings{
  li2024svdquant,
  title={SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models},
  author={Li*, Muyang and Lin*, Yujun and Zhang*, Zhekai and Cai, Tianle and Li, Xiuyu and Guo, Junxian and Xie, Enze and Meng, Chenlin and Zhu, Jun-Yan and Han, Song},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
```

## è‡´è°¢

æ„Ÿè°¢ MIT-IBM Watson AI Labã€MIT å’ŒAmazon Science Hubã€MIT AI Hardware Programã€National Science Foundationã€Packard Foundationã€Dellã€LGã€Hyundaiå’ŒSamsungå¯¹æœ¬ç ”ç©¶çš„æ”¯æŒã€‚æ„Ÿè°¢ NVIDIA æèµ  DGX æœåŠ¡å™¨ã€‚

æˆ‘ä»¬ä½¿ç”¨ [img2img-turbo](https://github.com/GaParmar/img2img-turbo) è®­ç»ƒè‰å›¾ç”Ÿæˆå›¾åƒçš„ LoRAã€‚æˆ‘ä»¬çš„æ–‡ç”Ÿå›¾å’Œå›¾åƒç”Ÿæˆç”¨æˆ·ç•Œé¢åŸºäº [playground-v.25](https://huggingface.co/spaces/playgroundai/playground-v2.5/blob/main/app.py) å’Œ [img2img-turbo](https://github.com/GaParmar/img2img-turbo/blob/main/gradio_sketch2image.py) æ„å»ºã€‚æˆ‘ä»¬çš„å®‰å…¨æ£€æŸ¥å™¨æ¥è‡ª [hart](https://github.com/mit-han-lab/hart)ã€‚

Nunchaku è¿˜å—åˆ°è®¸å¤šå¼€æºåº“çš„å¯å‘ï¼ŒåŒ…æ‹¬ï¼ˆä½†ä¸é™äºï¼‰[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)ã€[vLLM](https://github.com/vllm-project/vllm)ã€[QServe](https://github.com/mit-han-lab/qserve)ã€[AWQ](https://github.com/mit-han-lab/llm-awq)ã€[FlashAttention-2](https://github.com/Dao-AILab/flash-attention) å’Œ [Atom](https://github.com/efeslab/Atom)ã€‚
